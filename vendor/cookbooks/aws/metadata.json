{"name":"aws","version":"3.3.2","description":"Custom resources for managing AWS resources","long_description":"# aws Cookbook\n\n[![Build Status](https://travis-ci.org/chef-cookbooks/aws.svg?branch=master)](https://travis-ci.org/chef-cookbooks/aws) [![Cookbook Version](https://img.shields.io/cookbook/v/aws.svg)](https://supermarket.chef.io/cookbooks/aws)\n\nThis cookbook includes resources and providers to configure and manage Amazon Web Services components and offerings with the EC2 API. Currently supported resources:\n\n- EBS Volumes (`ebs_volume`)\n- EBS Raid (`ebs_raid`)\n- Elastic IPs (`elastic_ip`)\n- Elastic Load Balancer (`elastic_lb`)\n- AWS Resource Tags (`resource_tag`)\n- Secondary IPs (`secondary_ip`)\n- AWS Cloudwatch Instance Monitoring (`aws_instance_monitoring`)\n- CloudFormation Stack Management (`cloudformation_stack`)\n- Kinesis Stream Management (`kinesis_stream`)\n- IAM User, Group, Policy, and Role Management:\n  - (`iam_user`)\n  - (`iam_group`)\n  - (`iam_policy`)\n  - (`iam_role`)\n\nUnsupported AWS resources that have other cookbooks include but are not limited to:\n\n- [Route53](https://supermarket.chef.io/cookbooks/route53)\n- [aws_security](https://supermarket.chef.io/cookbooks/aws_security)\n\n## Requirements\n\n### Platforms\n\n- Any platform supported by Chef and the AWS-SDK\n\n### Chef\n\n- Chef 11.6+\n\n### Cookbooks\n\n- Ohai 2.1.0+\n\n## Credentials\n\nIn order to manage AWS components, authentication credentials need to be available to the node. There are 3 ways to handle this:\n\n1. explicitly pass credentials parameter to the resource\n2. use the credentials in the `~/.aws/credentials` file\n3. let the resource pick up credentials from the IAM role assigned to the instance\n\n**Also new** resources can now assume an STS role, with support for MFA as well. Instructions are below in the relevant section.\n\n### Using resource parameters\n\nIn order to pass the credentials to the resource, credentials must be available to the node. There are a number of ways to handle this, such as node attributes applied to the node or via Chef roles/environments.\n\nWe recommend storing these in an encrypted databag, and loading them in the recipe where the resources are used.\n\nExample Data Bag:\n\n```json\n% knife data bag show aws main\n{\n  \"id\": \"main\",\n  \"aws_access_key_id\": \"YOUR_ACCESS_KEY\",\n  \"aws_secret_access_key\": \"YOUR_SECRET_ACCESS_KEY\",\n  \"aws_session_token\": \"YOUR_SESSION_TOKEN\"\n}\n```\n\nThis can be loaded in a recipe with:\n\n```ruby\naws = data_bag_item('aws', 'main')\n```\n\nAnd to access the values:\n\n```ruby\naws['aws_access_key_id']\naws['aws_secret_access_key']\naws['aws_session_token']\n```\n\nWe'll look at specific usage below.\n\n### Using local credentials\n\nIf credentials are not supplied via parameters, resources will look for the credentials in the `~/.aws/credentials` file:\n\n```\n[default]\naws_access_key_id = ACCESS_KEY_ID\naws_secret_access_key = ACCESS_KEY\n```\n\nNote that this also accepts other profiles if they are supplied via the `ENV['AWS_PROFILE']` environment variable.\n\n### Using IAM instance role\n\nIf your instance has an IAM role, then the credentials can be automatically resolved by the cookbook using Amazon instance metadata API.\n\nYou can then omit the resource parameters `aws_secret_access_key` and `aws_access_key`.\n\nOf course, the instance role must have the required policies. Here is a sample policy for EBS volume management:\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"ec2:AttachVolume\",\n        \"ec2:CreateVolume\",\n        \"ec2:ModifyVolumeAttribute\",\n        \"ec2:DescribeVolumeAttribute\",\n        \"ec2:DescribeVolumeStatus\",\n        \"ec2:DescribeVolumes\",\n        \"ec2:DetachVolume\",\n        \"ec2:EnableVolumeIO\"\n      ],\n      \"Sid\": \"Stmt1381536011000\",\n      \"Resource\": [\n        \"*\"\n      ],\n      \"Effect\": \"Allow\"\n    }\n  ]\n}\n```\n\nFor resource tags:\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"ec2:CreateTags\",\n        \"ec2:DescribeTags\"\n      ],\n      \"Sid\": \"Stmt1381536708000\",\n      \"Resource\": [\n        \"*\"\n      ],\n      \"Effect\": \"Allow\"\n    }\n  ]\n}\n```\n\n### Assuming roles via STS and using MFA\n\nThe following is an example of how roles can be assumed using MFA. The following can also be used to assumes roles that do not require MFA, just ensure that the MFA arguments (`serial_number` and `token_code`) are omitted.\n\nThis assumes you have also stored the `cfn_role_arn`, and `mfa_serial` attributes as well, but there are plenty of ways these attributes can be supplied (they could be stored locally in the consuming cookbook, for example).\n\nNote that MFA codes cannot be recycled, hence the importance of creating a single STS session and passing that to resources. If multiple roles need to be assumed using MFA, it is probably prudent that these be broken up into different recipes and `chef-client` runs.\n\n```ruby\nrequire 'aws-sdk'\nrequire 'securerandom'\n\nsession_id = SecureRandom.hex(8)\nsts = ::Aws::AssumeRoleCredentials.new(\n  client: ::Aws::STS::Client.new(\n    credentials: ::Aws::Credentials.new(\n      node['aws']['aws_access_key_id'],\n      node['aws']['aws_secret_access_key']\n    ),\n    region: 'us-east-1'\n  ),\n  role_arn: node['aws']['cfn_role_arn'],\n  role_session_name: session_id,\n  serial_number: node['aws']['mfa_serial'],\n  token_code: node['aws']['mfa_code']\n)\n\naws_cloudformation_stack 'kitchen-test-stack' do\n  action :create\n  template_source 'kitchen-test-stack.tpl'\n  aws_access_key sts.access_key_id\n  aws_secret_access_key sts.secret_access_key\n  aws_session_token sts.session_token\nend\n```\n\nWhen running the cookbook, ensure that an attribute JSON is passed that supplies the MFA code. Example using chef-zero:\n\n```\necho '{ \"aws\": { \"mfa_code\": \"123456\" } }' > mfa.json && chef-client -z -o 'recipe[aws_test]' -j mfa.json\n```\n\n### Running outside of an AWS instance\n\n`region` can be specified if the cookbook is being run outside of an AWS instance. This can prevent some kinds of failures that happen when resources try to detect region.\n\n```ruby\naws_cloudformation_stack 'kitchen-test-stack' do\n  action :create\n  template_source 'kitchen-test-stack.tpl'\n  region 'us-east-1'\nend\n```\n\n## Recipes\n\n### default.rb\n\nThis recipe is empty.  In previous releases it installed the aws-sdk gem, but this is now performed automatically in the providers.\n\n### ec2_hints.rb\n\nThis recipe is used to setup the EC2 hints for Ohai in the case that an instance is not created using knife-ec2.\n\n## Resources and Providers\n\n### ebs_volume.rb\n\nManage Elastic Block Store (EBS) volumes with this resource.\n\n#### Actions:\n\n- `create` - create a new volume.\n- `attach` - attach the specified volume.\n- `detach` - detach the specified volume.\n- `delete` - delete the specified volume.\n- `snapshot` - create a snapshot of the volume.\n- `prune` - prune snapshots.\n\n#### Properties:\n\n- `aws_secret_access_key`, `aws_access_key` and optionally `aws_session_token` - required, unless using IAM roles for authentication.\n- `size` - size of the volume in gigabytes.\n- `snapshot_id` - snapshot to build EBS volume from.\n- `most_recent_snapshot` - use the most recent snapshot when creating a volume from an existing volume (defaults to false)\n- `availability_zone` - EC2 region, and is normally automatically detected.\n- `device` - local block device to attach the volume to, e.g. `/dev/sdi` but no default value, required.\n- `volume_id` - specify an ID to attach, cannot be used with action `:create` because AWS assigns new volume IDs\n- `timeout` - connection timeout for EC2 API.\n- `snapshots_to_keep` - used with action `:prune` for number of snapshots to maintain.\n- `description` - used to set the description of an EBS snapshot\n- `volume_type` - \"standard\", \"io1\", or \"gp2\" (\"standard\" is magnetic, \"io1\" is provisioned SSD, \"gp2\" is general purpose SSD)\n- `piops` - number of Provisioned IOPS to provision, must be >= 100\n- `existing_raid` - whether or not to assume the raid was previously assembled on existing volumes (default no)\n- `encrypted` - specify if the EBS should be encrypted\n- `kms_key_id` - the full ARN of the AWS Key Management Service (AWS KMS) master key to use when creating the encrypted volume (defaults to master key if not specified)\n- `delete_on_termination` - Boolean value to control whether or not the volume should be deleted when the instance it's attached to is terminated (defaults to nil).  Only applies to `:attach` action.\n\n### ebs_raid.rb\n\nManage Elastic Block Store (EBS) raid devices with this resource. This resource is linux specific and creates a mdadm array using EBS volumes.\n\n#### Actions:\n\n- `auto_attach` - create / mount raid array\n\n#### Properties:\n\n- `aws_secret_access_key`, `aws_access_key` and optionally `aws_session_token` - required, unless using IAM roles for authentication.\n- `mount_point` - where to mount the RAID volume\n- `mount_point_owner` - the owner of the mount point (default root)\n- `mount_point_group` - the group of the mount point (default root)\n- `mount_point_mode` - the file mode of the mount point (default 00755)\n- `disk_count` - number of EBS volumes to raid\n- `disk_size` - size of EBS volumes to raid\n- `level` - RAID level (default 10)\n- `filesystem` - filesystem to format raid array (default ext4 supported ext4 or xfs) _NOTE_ Using xfs assumes that you provide the underlying packages required for xfs to work.\n- `filesystem_options` - String of options to mount the filesystem with (default rw,noatime,nobootwait)\n- `snapshots` - array of EBS snapshots to restore. Snapshots must be taken using an ec2 consistent snapshot tool, and tagged with a number that indicates how many devices are in the array being backed up (e.g. \"Logs Backup [0-4]\" for a four-volume raid array snapshot)\n- `disk_type` - \"standard\", \"io1\", or \"gp2\" (\"standard\" is magnetic, \"io1\" is provisioned iops SSD, \"gp2\" is general purpose SSD)\n- `disk_piops` - number of Provisioned IOPS to provision per disk, must be > 100\n- `disk_encrypted` - specify if the EBS volumes should be encrypted\n- `disk_kms_key_id` - the full ARN of the AWS Key Management Service (AWS KMS) master key to use when creating the encrypted volumes (defaults to master key if not specified)\n\n### elastic_ip.rb\n\n#### Actions:\n\n- `associate` - associate the IP.\n- `disassociate` - disassociate the IP.\n\n#### Properties:\n\n- `aws_secret_access_key`, `aws_access_key` and optionally `aws_session_token` - passed to `Opscode::AWS:Ec2` to authenticate, required, unless using IAM roles for authentication.\n- `ip` - the IP address.\n- `timeout` - connection timeout for EC2 API.\n\n### elastic_lb.rb\n\n#### Actions:\n\n- `register` - Add this instance to the LB\n- `deregister` - Remove this instance from the LB\n\n#### Properties:\n\n- `aws_secret_access_key`, `aws_access_key` and optionally `aws_session_token` - passed to `Opscode::AWS:Ec2` to authenticate, required, unless using IAM roles for authentication.\n- `name` - the name of the LB, required.\n\n### resource_tag.rb\n\n#### Actions:\n\n- `add` - Add tags to a resource.\n- `update` - Add or modify existing tags on a resource -- this is the default action.\n- `remove` - Remove tags from a resource, but only if the specified values match the existing ones.\n- `force_remove` - Remove tags from a resource, regardless of their values.\n\n#### Properties:\n\n- `aws_secret_access_key`, `aws_access_key` and optionally `aws_session_token` - passed to `Opscode::AWS:Ec2` to authenticate, required, unless using IAM roles for authentication.\n- `tags` - a hash of key value pairs to be used as resource tags, (e.g. `{ \"Name\" => \"foo\", \"Environment\" => node.chef_environment }`,) required.\n- `resource_id` - resources whose tags will be modified. The value may be a single ID as a string or multiple IDs in an array. If no\n- `resource_id` is specified the name attribute will be used.\n\n### instance_monitoring.rb\n\n#### Actions:\n\n- `enable` - Enable detailed CloudWatch monitoring for this instance (Default).\n- `disable` - Disable detailed CloudWatch monitoring for this instance.\n\n#### Properties:\n\n- `aws_secret_access_key`, `aws_access_key` and optionally `aws_session_token` - passed to `Opscode::AWS:Ec2` to authenticate, required, unless using IAM roles for authentication.\n\n### secondary_ip.rb\n\nThis feature is available only to instances in EC2-VPC. It allows you to assign multiple private IP addresses to a network interface.\n\n#### Actions:\n\n- `assign` - Assign a private IP to the instance.\n- `unassign` - Unassign a private IP from the instance.\n\n#### Properties:\n\n- `aws_secret_access_key`, `aws_access_key` and optionally `aws_session_token` - passed to `Opscode::AWS:Ec2` to authenticate, required, unless using IAM roles for authentication.\n- `ip` - the private IP address. If none is given on assignment, will assign a random IP in the subnet.\n- `interface` - the network interface to assign the IP to. If none is given, uses the default interface.\n- `timeout` - connection timeout for EC2 API.\n\n## Usage\n\nThe following examples assume that the recommended data bag item has been created and that the following has been included at the top of the recipe where they are used.\n\n```ruby\ninclude_recipe 'aws'\naws = data_bag_item('aws', 'main')\n```\n\n### aws_ebs_volume\n\nThe resource only handles manipulating the EBS volume, additional resources need to be created in the recipe to manage the attached volume as a filesystem or logical volume.\n\n```ruby\naws_ebs_volume 'db_ebs_volume' do\n  aws_access_key aws['aws_access_key_id']\n  aws_secret_access_key aws['aws_secret_access_key']\n  size 50\n  device '/dev/sdi'\n  action [:create, :attach]\nend\n```\n\nThis will create a 50G volume, attach it to the instance as `/dev/sdi`.\n\n```ruby\naws_ebs_volume 'db_ebs_volume_from_snapshot' do\n  aws_access_key aws['aws_access_key_id']\n  aws_secret_access_key aws['aws_secret_access_key']\n  size 50\n  device '/dev/sdi'\n  snapshot_id 'snap-ABCDEFGH'\n  action [:create, :attach]\nend\n```\n\nThis will create a new 50G volume from the snapshot ID provided and attach it as `/dev/sdi`.\n\n### aws_elastic_ip\n\nThe `elastic_ip` resource provider does not support allocating new IPs. This must be done before running a recipe that uses the resource. After allocating a new Elastic IP, we recommend storing it in a databag and loading the item in the recipe.\n\nDatabag structure:\n\n```json\n% knife data bag show aws eip_load_balancer_production\n{\n  \"id\": \"eip_load_balancer_production\",\n  \"public_ip\": \"YOUR_ALLOCATED_IP\"\n}\n```\n\nThen to set up the Elastic IP on a system:\n\n```ruby\nip_info = data_bag_item('aws', 'eip_load_balancer_production')\n\naws_elastic_ip 'eip_load_balancer_production' do\n  aws_access_key aws['aws_access_key_id']\n  aws_secret_access_key aws['aws_secret_access_key']\n  ip ip_info['public_ip']\n  action :associate\nend\n```\n\nThis will use the loaded `aws` and `ip_info` databags to pass the required values into the resource to configure. Note that when associating an Elastic IP to an instance, connectivity to the instance will be lost because the public IP address is changed. You will need to reconnect to the instance with the new IP.\n\nYou can also store this in a role as an attribute or assign to the node directly, if preferred.\n\n### aws_elastic_lb\n\n`elastic_lb` functions similarly to `elastic_ip`. Make sure that you've created the ELB and enabled your instances' availability zones prior to using this provider.\n\nFor example, to register the node in the 'QA' ELB:\n\n```ruby\naws_elastic_lb 'elb_qa' do\n  aws_access_key aws['aws_access_key_id']\n  aws_secret_access_key aws['aws_secret_access_key']\n  name 'QA'\n  action :register\nend\n```\n\n### aws_resource_tag\n\n`resource_tag` can be used to manipulate the tags assigned to one or more AWS resources, i.e. ec2 instances, ebs volumes or ebs volume snapshots.\n\nAssigning tags to a node to reflect its role and environment:\n\n```ruby\naws_resource_tag node['ec2']['instance_id'] do\n  aws_access_key aws['aws_access_key_id']\n  aws_secret_access_key aws['aws_secret_access_key']\n  tags('Name' => 'www.example.com app server',\n       'Environment' => node.chef_environment)\n  action :update\nend\n```\n\nAssigning a set of tags to multiple resources, e.g. ebs volumes in a disk set:\n\n```ruby\naws_resource_tag 'my awesome raid set' do\n  aws_access_key aws['aws_access_key_id']\n  aws_secret_access_key aws['aws_secret_access_key']\n  resource_id ['vol-d0518cb2', 'vol-fad31a9a', 'vol-fb106a9f', 'vol-74ed3b14']\n  tags('Name' => 'My awesome RAID disk set',\n       'Environment' => node.chef_environment)\nend\n```\n\n```ruby\naws_resource_tag 'db_ebs_volume' do\n  resource_id lazy { node['aws']['ebs_volume']['db_ebs_volume']['volume_id'] }\n  tags ({ 'Service' => 'Frontend' })\nend\n```\n\n### aws_s3_file\n\n`s3_file` can be used to download a file from s3 that requires aws authorization.  This is a wrapper around the core chef `remote_file` resource and supports the same resource attributes as `remote_file`. See [remote_file Chef Docs] (<https://docs.chef.io/resource_remote_file.html>) for a complete list of available attributes.\n\n```ruby\naws_s3_file '/tmp/foo' do\n  bucket 'i_haz_an_s3_buckit'\n  remote_path 'path/in/s3/bukket/to/foo'\n  aws_access_key aws['aws_access_key_id']\n  aws_secret_access_key aws['aws_secret_access_key']\n  region 'us-west-1'\nend\n```\n\n## aws_instance_monitoring\n\nAllows detailed CloudWatch monitoring to be enabled for the current instance.\n\n```ruby\naws_instance_monitoring \"enable detailed monitoring\"\n```\n\n## aws_secondary_ip\n\nThe `secondary_ip` resource provider allows one to assign/unassign multiple private secondary IPs on an instance in EC2-VPC. The number of secondary IP addresses that you can assign to an instance varies by instance type. If no ip address is provided on assign, a random one from within the subnet will be assigned. If no interface is provided, the default interface (which is pulled from Ohai) will be used.\n\n```ruby\naws_secondary_ip \"assign_additional_ip\" do\n  aws_access_key aws['aws_access_key_id']\n  aws_secret_access_key aws['aws_secret_access_key']\n  ip ip_info['private_ip']\n  interface 'eth0'\n  action :assign\nend\n```\n\n## aws_cloudformation_stack\n\nManage CloudFormation stacks with Chef.\n\nExample:\n\n```ruby\naws_cloudformation_stack 'example-stack' do\n  region 'us-east-1'\n  template_source 'example-stack.tpl'\n\n  parameters ([\n    {\n      :parameter_key => 'KeyPair',\n      :parameter_value => 'user@host'\n    },\n    {\n      :parameter_key => 'SSHAllowIPAddress',\n      :parameter_value => '127.0.0.1/32'\n    }\n  ])\nend\n```\n\nActions:\n\n- `create`: Creates the stack, or updates it if it already exists.\n- `delete`: Begins the deletion process for the stack.\n\nAttribute parameters are:\n\n- `template_source`: Required - the location of the CloudFormation template file. The file should be stored in the `files` directory in the cookbook.\n- `parameters`: An array of `parameter_key` and `parameter_value` pairs for parameters in the template. Follow the syntax in the example above.\n- `disable_rollback`: Set this to `true` if you want stack rollback to be disabled if creation of the stack fails. Default: `false`\n- `stack_policy_body`: Optionally define a stack policy to apply to the stack, mainly used in protecting stack resources after they are created. For more information, see [Prevent Updates to Stack Resources](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html) in the CloudFormation user guide.\n- `iam_capability`: Set to `true` to allow the CloudFormation template to create IAM resources. This is the equivalent of setting `CAPABILITY_IAM` When using the SDK or CLI. Default: `false`\n\n## aws_dynamodb_table\n\nUse this resource to create and delete DynamoDB tables. This includes the ability to add global secondary indexes to existing tables.\n\n```ruby\naws_dynamodb_table 'example-table' do\n  action :create\n  attribute_definitions [\n    { attribute_name: 'Id', attribute_type: 'N' },\n    { attribute_name: 'Foo', attribute_type: 'N' },\n    { attribute_name: 'Bar', attribute_type: 'N' },\n    { attribute_name: 'Baz', attribute_type: 'S' }\n  ]\n  key_schema [\n    { attribute_name: 'Id', key_type: 'HASH' },\n    { attribute_name: 'Foo', key_type: 'RANGE' }\n  ]\n  local_secondary_indexes [\n    {\n      index_name: 'BarIndex',\n      key_schema: [\n        {\n          attribute_name: 'Id',\n          key_type: 'HASH'\n        },\n        {\n          attribute_name: 'Bar',\n          key_type: 'RANGE'\n        }\n      ],\n      projection: {\n        projection_type: 'ALL'\n      }\n    }\n  ]\n  global_secondary_indexes [\n    {\n      index_name: 'BazIndex',\n      key_schema: [{\n        attribute_name: 'Baz',\n        key_type: 'HASH'\n      }],\n      projection: {\n        projection_type: 'ALL'\n      },\n      provisioned_throughput: {\n        read_capacity_units: 1,\n        write_capacity_units: 1\n      }\n    }\n  ]\n  provisioned_throughput ({\n    read_capacity_units: 1,\n    write_capacity_units: 1\n  })\n  stream_specification ({\n    stream_enabled: true,\n    stream_view_type: 'KEYS_ONLY'\n  })\nend\n```\n\nActions:\n\n- `create`: Creates the table. Will update the following if the table exists:\n\n  - `global_secondary_indexes`: Will remove non-existent indexes, add new ones, and update throughput for existing ones. All attributes need to be present in `attribute_definitions`. No effect if the resource is omitted.\n  - `stream_specification`: Will update as shown. No effect is the resource is omitted.\n  - `provisioned_throughput`: Will update as shown.\n\n- `delete`: Deletes the index.\n\nAttributes:\n\n- `attribute_definitions`: Required. Attributes to create for the table. Mainly this is used to specify attributes that are used in keys, as otherwise one can add any attribute they want to a DynamoDB table.\n- `key_schema`: Required. Used to create the primary key for the table. Attributes need to be present in `attribute_definitions`.\n- `local_secondary_indexes`: Used to create any local secondary indexes for the table. Attributes need to be present in `attribute_definitions`.\n- `global_secondary_indexes`: Used to create any global secondary indexes. Can be done to an existing table. Attributes need to be present in\n- `attribute_definitions`.\n- `provisioned_throughput`: Define the throughput for this table.\n- `stream_specification`: Specify if there should be a stream for this table.\n\nSeveral of the attributes shown here take parameters as shown in the [AWS Ruby SDK Documentation](http://docs.aws.amazon.com/sdkforruby/api/Aws/DynamoDB/Client.html#create_table-instance_method). Also, the [AWS DynamoDB Documentation](http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html) may be of further help as well.\n\n## aws_kinesis_stream\n\nUse this resource to create and delete Kinesis streams. Note that this resource cannot be used to modify the shard count as shard splitting is a somewhat complex operation (for example, even CloudFormation replaces streams upon update).\n\n```ruby\naws_kinesis_stream 'example-stream' do\n action :create\n starting_shard_count 1\nend\n```\n\nActions:\n\n- `create`: Creates the stream. No effect if the stream already exists.\n- `delete`: Deletes the stream.\n\nUse `starting_shard_count` to control the amount of shards the stream starts with.\n\n## aws_iam_user\n\nUse this resource to manage IAM users.\n\n```ruby\naws_iam_user 'example-user' do\n  action :create\n  path '/'\nend\n```\n\nActions:\n\n- `create`: Creates the user. No effect if the user already exists.\n- `delete`: Gracefully deletes the user (detaches from all attached entities, and deletes the user).\n\nThe IAM user takes the name of the resource. A `path` can be specified as well. For more information about paths, see [IAM Identifiers](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html) in the Using IAM guide.\n\n## aws_iam_group\n\nUse this resource to manage IAM groups. The group takes the name of the resource.\n\n```ruby\naws_iam_group 'example-group' do\n  action :create\n  path '/'\n  members [\n    'example-user'\n  ]\n  remove_members true\n  policy_members [\n    'arn:aws:iam::123456789012:policy/example-policy'\n  ]\n  remove_policy_members true\nend\n```\n\nActions:\n\n- `create`: Creates the group, and updates members and attached policies if the group already exists.\n- `delete`: Gracefully deletes the group (detaches from all attached entities, and deletes the group).\n\nAttribute parameters are:\n\n- `path`: A path can be supplied for the group. For information on paths, see [IAM Identifiers](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html) in the Using IAM guide.\n- `members`: An array of IAM users that are a member of this group.\n- `remove_members`: Set to `false` to ensure that members are not removed from the group when they are not present in the defined resource. Default: `true`\n- `policy_members`: An array of ARNs of IAM managed policies to attach to this resource. Accepts both user-defined and AWS-defined policy ARNs.\n- `remove_policy_members`: Set to `false` to ensure that policies are not detached from the group when they are not present in the defined resource. Default: `true`\n\n## aws_iam_policy\n\nUse this resource to create an IAM policy. The policy takes the name of the resource.\n\n```ruby\naws_iam_policy 'example-policy' do\n  action :create\n  path '/'\n  account_id '123456789012'\n  policy_document <<-EOH.gsub(/^ {4}/, '')\n    {\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [\n            {\n                \"Sid\": \"Stmt1234567890\",\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"sts:AssumeRole\"\n                ],\n                \"Resource\": [\n                    \"arn:aws:iam::123456789012:role/example-role\"\n                ]\n            }\n        ]\n    }\n  EOH\nend\n```\n\nActions:\n\n- `create`: Creates or updates the policy.\n- `delete`: Gracefully deletes the policy (detaches from all attached entities, deletes all non-default policy versions, then deletes the policy).\n\nAttribute parameters are:\n\n- `path`: A path can be supplied for the group. For information on paths, see [IAM Identifiers](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html) in the Using IAM guide.\n- `policy_document`: The JSON document for the policy.\n- `account_id`: The AWS account ID that the policy is going in. Required if using non-user credentials (ie: IAM role through STS or instance role).\n\n## aws_iam_role\n\nUse this resource to create an IAM role. The policy takes the name of the resource.\n\n```ruby\naws_iam_role 'example-role' do\n  action :create\n  path '/'\n  policy_members [\n    'arn:aws:iam::123456789012:policy/example-policy'\n  ]\n  remove_policy_members true\n  assume_role_policy_document <<-EOH.gsub(/^ {4}/, '')\n    {\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n        {\n          \"Sid\": \"\",\n          \"Effect\": \"Deny\",\n          \"Principal\": {\n            \"AWS\": \"*\"\n          },\n          \"Action\": \"sts:AssumeRole\"\n        }\n      ]\n    }\n  EOH\nend\n```\n\n- `create`: Creates the role if it does not exist. If the role exists, updates attached policies and the `assume_role_policy_document`.\n- `delete`: Gracefully deletes the role (detaches from all attached entities, and deletes the role).\n\nAttribute parameters are:\n\n- `path`: A path can be supplied for the group. For information on paths, see [IAM Identifiers](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html) in the Using IAM guide.\n- `policy_members`: An array of ARNs of IAM managed policies to attach to this resource. Accepts both user-defined and AWS-defined policy ARNs.\n- `remove_policy_members`: Set to `false` to ensure that policies are not detached from the group when they are not present in the defined resource. Default: `true`\n- `assume_role_policy_document`: The JSON policy document to apply to this role for trust relationships. Dictates what entities can assume this role.\n\n## License and Authors\n\n- Author:: Chris Walters ([cw@chef.io](mailto:cw@chef.io))\n- Author:: AJ Christensen ([aj@chef.io](mailto:aj@chef.io))\n- Author:: Justin Huff ([jjhuff@mspin.net](mailto:jjhuff@mspin.net))\n\nCopyright 2009-2015, Chef Software, Inc.\n\n```\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n","maintainer":"Chef Software, Inc.","maintainer_email":"cookbooks@chef.io","license":"Apache 2.0","platforms":{"ubuntu":">= 0.0.0","debian":">= 0.0.0","centos":">= 0.0.0","redhat":">= 0.0.0","amazon":">= 0.0.0","scientific":">= 0.0.0","fedora":">= 0.0.0","oracle":">= 0.0.0","freebsd":">= 0.0.0","windows":">= 0.0.0"},"dependencies":{"ohai":">= 2.1.0"},"recommendations":{},"suggestions":{},"conflicting":{},"providing":{},"replacing":{},"attributes":{},"groupings":{},"recipes":{"aws":"Installs the aws-sdk gem during compile time","ec2_hints":"Adds an EC2 hint file for Ohai cloud detection"}}